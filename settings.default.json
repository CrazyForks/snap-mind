{
  "general": {
    "language": "",
    "clipboardEnabled": true,
    "autoUpdate": {
      "enabled": true,
      "checkOnLaunchDelaySec": 10,
      "betaChannel": false
    }
  },
  "chat": {
    "temperature": 0.7,
    "max_tokens": 2048,
    "top_p": 0.95,
    "streamingEnabled": true,
    "defaultModel": null
  },
  "providers": [
    {
      "id": "openai",
      "name": "OpenAI",
      "apiKey": "",
      "host": "https://api.openai.com/v1",
      "models": [
        {
          "id": "gpt-4",
          "name": "GPT-4",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Latest model from OpenAI"
        },
        {
          "id": "gpt-3.5",
          "name": "GPT-3.5",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Previous generation model"
        }
      ]
    },
    {
      "id": "azure-openai",
      "name": "Azure OpenAI",
      "apiKey": "",
      "apiVersion": "",
      "host": "https://your-resource.openai.azure.com",
      "description": "For Azure OpenAI, you can provide either a base endpoint (e.g., https://your-resource.openai.azure.com) or a complete endpoint URL (e.g., https://your-resource.openai.azure.com/openai/deployments/your-deployment-name/chat/completions?api-version=2023-05-15)",
      "models": [
        {
          "id": "gpt-4o",
          "name": "Azure GPT-4o",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Azure GPT-4o"
        }
      ]
    },
    {
      "id": "anthropic",
      "name": "Anthropic",
      "apiKey": "",
      "host": "https://api.anthropic.com/v1/messages",
      "models": [
        {
          "id": "claude-3-opus-20240229",
          "name": "Claude 3 Opus",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Most powerful Claude model for highly complex tasks"
        },
        {
          "id": "claude-3-sonnet-20240229",
          "name": "Claude 3 Sonnet",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Balanced Claude model for most tasks"
        },
        {
          "id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Fastest, most compact Claude model"
        }
      ]
    },
    {
      "id": "google",
      "name": "Google AI",
      "apiKey": "",
      "host": "https://generativelanguage.googleapis.com/v1beta",
      "config": {
        "topK": 40
      },
      "models": [
        {
          "id": "gemini-1.5-pro",
          "name": "Gemini 1.5 Pro",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Highly capable multimodal model"
        },
        {
          "id": "gemini-1.5-flash",
          "name": "Gemini 1.5 Flash",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Fast and efficient model for most tasks"
        }
      ]
    },
    {
      "id": "deepseek",
      "name": "DeepSeek",
      "apiKey": "",
      "host": "https://api.deepseek.com/chat/completions",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "DeepSeek Chat",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "DeepSeek general chat model"
        },
        {
          "id": "deepseek-reasoner",
          "name": "DeepSeek Reasoner",
          "type": "chat",
          "capabilities": ["chat", "reasoning"],
          "description": "Reasoning-optimized model"
        }
      ]
    },
    {
      "id": "qwen",
      "name": "Qwen",
      "apiKey": "",
      "host": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
      "models": [
        {
          "id": "qwen-plus",
          "name": "Qwen Plus",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Balanced Qwen model"
        },
        {
          "id": "qwen-max",
          "name": "Qwen Max",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Most capable Qwen model"
        },
        {
          "id": "qwen-turbo",
          "name": "Qwen Turbo",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Fast and efficient Qwen model"
        }
      ]
    },
    {
      "id": "ollama",
      "name": "Ollama (Local)",
      "apiKey": "",
      "host": "http://localhost:11434/api/chat",
      "description": "Use local models served by the Ollama runtime",
      "models": [
        {
          "id": "llama3.2",
          "name": "llama3.2",
          "type": "chat",
          "capabilities": ["chat"],
          "description": "Default sample model name; replace with your local models"
        }
      ]
    }
  ]
}
